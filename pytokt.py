# -*- coding: utf-8 -*-
"""pytokt.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FQFLmZFSgSjTsRyh2IshxlW6pGDdsOeq
"""

import matplotlib.pyplot as plt
import os
import cv2
import numpy as np
from joblib import load
import pickle
from datetime import datetime
from PIL import Image
import tensorflow as tf

def process_image(image_path):
    img0 = cv2.imread(image_path)

    def rotate_to_match(image_path1):
        image = Image.open(image_path1)
        if image.width > image.height :
            image = image.transpose(Image.ROTATE_270)
        return image

    rotated_image = rotate_to_match(image_path)

    opencv_image_rotated = np.array(rotated_image)

    # Convert color channel order from RGB (PIL) to BGR (OpenCV)
    opencv_image_rotated = cv2.cvtColor(opencv_image_rotated, cv2.COLOR_RGB2BGR)

    resized_image1 = cv2.resize(img0, (800, 600))

    resized_image = opencv_image_rotated

    width1, height1, _ = resized_image.shape
    dim_org = [width1, height1]

    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)
    img_blur = cv2.GaussianBlur(gray_image, (7, 7), sigmaX=0, sigmaY=0)

    lower = 0  # Example lower intensity threshold
    upper = 160  # Example upper intensity threshold

    mask = cv2.inRange(img_blur, lower, upper)
    ret, thresh = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)

    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    areas = [cv2.contourArea(c) for c in contours]
    max_index = np.argmax(areas)
    cnt = contours[max_index]

    rect = cv2.minAreaRect(cnt)
    rect_points = cv2.boxPoints(rect)
    rect_points = np.int0(rect_points)
    max_contour = max(contours, key=cv2.contourArea)
    contours_sorted = sorted(contours, key=cv2.contourArea, reverse=True)
    epsilon = 0.05 * cv2.arcLength(contours_sorted[2], True)
    approx = cv2.approxPolyDP(contours_sorted[2], epsilon, True)

    if len(approx) != 4:
        epsilon = 0.05 * cv2.arcLength(contours_sorted[1], True)
        approx = cv2.approxPolyDP(contours_sorted[1], epsilon, True)

    if len(approx) != 4:
        epsilon = 0.05 * cv2.arcLength(contours_sorted[0], True)
        approx = cv2.approxPolyDP(contours_sorted[0], epsilon, True)

    sorted_coords = sorted(approx, key=lambda x: x[0][0] + x[0][1])

    bottom_left = sorted_coords[0]
    sorted_coords.pop(0)
    top_right = sorted_coords[2]
    sorted_coords.pop(2)

    if sorted_coords[0][0][1] > sorted_coords[1][0][1]:
        selected_coordinate = sorted_coords[0]
        sorted_coords.pop(0)
    else:
        selected_coordinate = sorted_coords[1]
        sorted_coords.pop(1)

    top_left = selected_coordinate
    bottom_right = sorted_coords[0]

    pt_A = bottom_left
    pt_B = top_left
    pt_C = top_right
    pt_D = bottom_right

    width_AD = np.sqrt(((pt_A[0, 0] - pt_D[0, 0]) ** 2) + ((pt_A[0, 1] - pt_D[0, 1]) ** 2))
    width_BC = np.sqrt(((pt_B[0, 0] - pt_C[0, 0]) ** 2) + ((pt_B[0, 1] - pt_C[0, 1]) ** 2))
    maxWidth = max(int(width_AD), int(width_BC))

    height_AB = np.sqrt(((pt_A[0, 0] - pt_B[0, 0]) ** 2) + ((pt_A[0, 1] - pt_B[0, 1]) ** 2))
    height_CD = np.sqrt(((pt_C[0, 0] - pt_D[0, 0]) ** 2) + ((pt_C[0, 1] - pt_D[0, 1]) ** 2))
    maxHeight = max(int(height_AB), int(height_CD))

    input_pts = np.float32([pt_A, pt_B, pt_C, pt_D])
    output_pts = np.float32([[0, 0],
                             [0, maxHeight - 1],
                             [maxWidth - 1, maxHeight - 1],
                             [maxWidth - 1, 0]])

    M = cv2.getPerspectiveTransform(input_pts, output_pts)
    out = cv2.warpPerspective(resized_image, M, (maxWidth, maxHeight), flags=cv2.INTER_LINEAR)

    rotated_image = out
    source = rotated_image
    width, height, _ = source.shape
    dim = [width, height]
    source = cv2.resize(rotated_image, (5412, 6142), interpolation=cv2.INTER_CUBIC)

    # return source

    interpreter = tf.lite.Interpreter(model_path="/content/best5_float32.tflite")
    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    print("input_details : ",input_details)
    print("output : ",output_details)

    input_shape = input_details[0]['shape'][1:3]
    print("inputshape : ",input_shape)

    # Resize and normalize the image
    resized_image = cv2.resize(source, tuple(input_shape))
    input_data = np.expand_dims(resized_image, axis=0).astype(np.float32)  # Convert to float32

    # Normalize the image if required by the model
    input_data = input_data / 255.0

    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()

    output_data = interpreter.get_tensor(output_details[0]['index'])

    return output_data,source

output,tim = process_image("/content/tflitetest.jpg")
# print(output)
# print(output.shape)

import numpy as np
import cv2


def decode_model_output(output, confidence_threshold=0.5, nms_threshold=0.5):
    # Assuming output shape is (batches, 4 + num_classes, num_candidate_detections)
    xc, yc, w, h = output[0, :4, :]
    confidences = output[0, 4:, :]
    # Reshape the boxes from (4, 821) to (821, 4)
    boxes = np.stack([xc, yc, w, h], axis=0).transpose(1, 0)
    # Apply confidence threshold
    mask = confidences > confidence_threshold
    boxes = boxes[mask[0], :]
    confidences = confidences[mask]

    # Apply Non-Maximal Suppression
    x1 = boxes[:, 0] - (boxes[:, 2] / 2)
    y1 = boxes[:, 1] - (boxes[:, 3] / 2)
    x2 = boxes[:, 0] + (boxes[:, 2] / 2)
    y2 = boxes[:, 1] + (boxes[:, 3] / 2)

    # indices = cv2.dnn.NMSBoxes(boxes.tolist(), confidences.tolist(), score_threshold=0.5, nms_threshold=0.1)

    # return indices,boxes,confidences




    return boxes, confidences
# test,conf = decode_model_output(output)
boxx,conff = decode_model_output(output)

class Box:
    def __init__(self, x, y, width, height):
        self.x = x
        self.y = y
        self.width = width
        self.height = height

class Detection:
    def __init__(self, box, confidence):
        self.box = box
        self.confidence = confidence

def non_maximum_suppression(boxes, confidences, score_threshold, nms_threshold):
    selected_indices = []

    # Filter out boxes with low confidence scores
    filtered_indices = [i for i in range(len(confidences)) if confidences[i] > score_threshold]

    # Sort indices based on confidence scores (higher confidence first)
    sorted_indices = sorted(filtered_indices, key=lambda i: confidences[i], reverse=True)

    while sorted_indices:
        current_idx = sorted_indices[0]
        selected_indices.append(current_idx)

        current_box = boxes[current_idx]
        remaining_indices = sorted_indices[1:]

        # Remove boxes that have high IoU with the selected box
        sorted_indices = [idx for idx in remaining_indices if compute_iou(current_box, boxes[idx]) <= nms_threshold]

    return selected_indices

def compute_iou(boxA, boxB):
    xA = max(boxA.x, boxB.x)
    yA = max(boxA.y, boxB.y)
    xB = min(boxA.x + boxA.width, boxB.x + boxB.width)
    yB = min(boxA.y + boxA.height, boxB.y + boxB.height)

    intersection_area = max(0, xB - xA) * max(0, yB - yA)
    boxA_area = boxA.width * boxA.height
    boxB_area = boxB.width * boxB.height

    return intersection_area / float(boxA_area + boxB_area - intersection_area)


boxes = [Box(x,y,w,h) for x,y,w,h in boxx]

confidences = conff

selected_indices = non_maximum_suppression(boxes, confidences, score_threshold=0.5, nms_threshold=0.5)

boxxes = [boxes[i] for i in selected_indices]
conffs = [confidences[i] for i in selected_indices]

image = np.copy(tim)

rice_type=[]
chalkiness=[]
pos=[]
ar=[]
length=[]
breadth=[]
index=[]
tbas=0
tnbas=0

filtered_coords = []
for box in boxxes:

    x,y,w,h = box.x, box.y, box.width, box.height

    startX = x-(w/2)
    startY = y-(h/2)
    endX = x+(w/2)
    endY = y+(h/2)


    startX, startY, endX, endY = int(startX*5412), int(startY*6142), int(endX*5412), int(endY*6142)
    filtered_coords.append([startX, startY, endX, endY])

mult1 = 60/len(tim)
mult2 = 60/len(tim[0])
timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

for i, (startX, startY, endX, endY) in enumerate(filtered_coords):

    startX, startY, endX, endY = int(startX), int(startY), int(endX), int(endY)
    roi = image[startY:endY, startX:endX]
    img_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    img_blur = cv2.GaussianBlur(img_gray, (7, 7), sigmaX=0, sigmaY=0)
    ret, thresh = cv2.threshold(img_blur, 155, 255, cv2.THRESH_BINARY) #73

    # Calculate proportion of white pixels
    white_pixels = cv2.countNonZero(thresh)
    total_pixels = thresh.size
    white_proportion = white_pixels / total_pixels

    if white_proportion >= 0.17:  # Adjust this threshold as needed
        # Find contours
        contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        if contours:
            # Find the index of the largest contour
            areas = [cv2.contourArea(c) for c in contours]
            max_index = np.argmax(areas)
            cnt = contours[max_index]


            M = cv2.moments(cnt)
            # Calculate centroid coordinates
            centroid_x = int(M["m10"] / M["m00"])
            centroid_y = int(M["m01"] / M["m00"])

            height = thresh.shape[0]
            y1_i = centroid_y
            y2_i = centroid_y

            k=0
            while(k+centroid_y<height-1):

                if thresh[k+centroid_y][centroid_x] != thresh[k+centroid_y+1][centroid_x]:
                    y1_i = k+centroid_y
                    break
                k=k+1

            j=0

            while(centroid_y-j>=0):
                if thresh[centroid_y-j][centroid_x] != thresh[centroid_y-j-1][centroid_x]:
                    y2_i = centroid_y - j
                    break
                j=j+1


            rect = cv2.minAreaRect(cnt)
            rect_points = cv2.boxPoints(rect)
            rect_points = np.int0(rect_points)

            h1,w1 = rect[1]


            if h1>=w1:
                l1 = h1*mult2
                b1 = w1*mult1

            else:
                l1 = w1*mult2
                b1 = h1*mult1
                h1,w1 = w1,h1


            x1, y1, w2, h2 = cv2.boundingRect(cnt)


            X_test = np.array([[l1]])

            b1 = (y1_i-y2_i)*mult1
            breadth.append(b1)


            adjusted_box = rect_points.copy()
            adjusted_box[:, 0] += startX  # Adjust x coordinates
            adjusted_box[:, 1] += startY  # Adjust y coordinates
            # Draw bounding box on original image
            cv2.drawContours(image, [adjusted_box], 0, (0, 255, 0), 10)

            aspect_ratio = float(h1) / w1
            ar.append(aspect_ratio)
            index.append(i)

            ret1, thresh1 = cv2.threshold(img_blur, 207, 255, cv2.THRESH_BINARY) #150

            white1 = cv2.countNonZero(thresh1)
            total1 = thresh1.size
            white_proportion1 = white1 / total1

            if l1<6.61:
                rice_type.append(f"Non-Basmati_{i}")
                cv2.putText(image, str(i), (startX+x1, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16) #y=10
                cv2.putText(image, "NB", (startX+x1+220, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16) #70 (255,0,0)
                pos.append(filtered_coords[i])
                tnbas=tnbas+1
                # cv2.drawContours(tempimg, [cnt], -1, (0, 0, 255), thickness=cv2.FILLED)
                if white_proportion1 >= 0.02:
                    chalkiness.append(f"chalky_{i}")
                    cv2.putText(image, "C", (startX+x1+500, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16) #130
                else:
                    chalkiness.append(f"non-chalky_{i}")
                    cv2.putText(image, "NC", (startX+x1+500, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16)


            elif b1>2.01:
                rice_type.append(f"Non-Basmati_{i}")
                cv2.putText(image, str(i), (startX+x1, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16)
                cv2.putText(image, "NB", (startX+x1+220, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16)
                pos.append(filtered_coords[i])
                tnbas=tnbas+1
                # cv2.drawContours(tempimg, [cnt], -1, (0, 0, 255), thickness=cv2.FILLED)
                if white_proportion1 >= 0.02:
                    chalkiness.append(f"chalky_{i}")
                    cv2.putText(image, "C", (startX+x1+500, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16)
                else:
                    chalkiness.append(f"non-chalky_{i}")
                    cv2.putText(image, "NC", (startX+x1+500, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16)

            elif aspect_ratio < 3.5:
                rice_type.append(f"Non-Basmati_{i}")
                cv2.putText(image, str(i), (startX+x1, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16)
                cv2.putText(image, "NB", (startX+x1+220, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16)
                pos.append(filtered_coords[i])
                tnbas=tnbas+1
                # cv2.drawContours(tempimg, [cnt], -1, (0, 0, 255), thickness=cv2.FILLED)
                if white_proportion1 >= 0.02:
                    chalkiness.append(f"chalky_{i}")
                    cv2.putText(image, "C", (startX+x1+500, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16)
                else:
                    chalkiness.append(f"non-chalky_{i}")
                    cv2.putText(image, "NC", (startX+x1+500, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 0), 16)
            else:
                rice_type.append(f"Basmati_{i}")
                cv2.putText(image, str(i), (startX+x1, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 255), 16)
                cv2.putText(image, "B", (startX+x1+220, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 255), 16)
                pos.append(filtered_coords[i])
                tbas=tbas+1
                # cv2.drawContours(tempimg, [cnt], -1, (255, 0, 0), thickness=cv2.FILLED)
                if white_proportion1 >= 0.02:
                    chalkiness.append(f"chalky_{i}")
                    cv2.putText(image, "C", (startX+x1+500, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 255), 16)

                else:
                    chalkiness.append(f"non-chalky_{i}")
                    cv2.putText(image, "NC", (startX+x1+500, startY+y1+100), cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 255), 16)


        else:
            #print("Not enough white pixels at position")
            pass

plt.imshow(image)

